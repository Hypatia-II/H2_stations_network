{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_preprocess.functions import Data\n",
    "from load_preprocess.predictions import Number_Stations\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import config\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import LineString, mapping\n",
    "from itertools import combinations\n",
    "import re\n",
    "from scipy import spatial\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from shapely import wkt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>road_density</th>\n",
       "      <th>length_m</th>\n",
       "      <th>area_m</th>\n",
       "      <th>length_max</th>\n",
       "      <th>length_mean</th>\n",
       "      <th>diameter</th>\n",
       "      <th>longest_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>2.744410e+06</td>\n",
       "      <td>1.206353e+10</td>\n",
       "      <td>85932.399845</td>\n",
       "      <td>3076.692877</td>\n",
       "      <td>123934.499714</td>\n",
       "      <td>162432.991960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nord-Pas-de-Calais</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.887368e+06</td>\n",
       "      <td>1.249483e+10</td>\n",
       "      <td>147881.271737</td>\n",
       "      <td>4015.676440</td>\n",
       "      <td>126130.541927</td>\n",
       "      <td>208410.677869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Haute-Normandie</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1.398489e+06</td>\n",
       "      <td>1.237197e+10</td>\n",
       "      <td>135138.054662</td>\n",
       "      <td>4994.602982</td>\n",
       "      <td>125508.904876</td>\n",
       "      <td>163440.964713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alsace</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>8.836421e+05</td>\n",
       "      <td>8.322648e+09</td>\n",
       "      <td>171172.687144</td>\n",
       "      <td>4374.466068</td>\n",
       "      <td>102940.396161</td>\n",
       "      <td>188809.381774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Picardie</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>1.822331e+06</td>\n",
       "      <td>1.954720e+10</td>\n",
       "      <td>163238.986421</td>\n",
       "      <td>7854.875311</td>\n",
       "      <td>157760.172316</td>\n",
       "      <td>218702.689596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rhône-Alpes</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>4.039422e+06</td>\n",
       "      <td>4.497380e+10</td>\n",
       "      <td>203474.560283</td>\n",
       "      <td>4047.517513</td>\n",
       "      <td>239295.676544</td>\n",
       "      <td>319508.048270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lorraine</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.007468e+06</td>\n",
       "      <td>2.366142e+10</td>\n",
       "      <td>189457.934215</td>\n",
       "      <td>4562.427574</td>\n",
       "      <td>173570.336256</td>\n",
       "      <td>235280.099059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bretagne</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.333729e+06</td>\n",
       "      <td>2.760417e+10</td>\n",
       "      <td>244626.451176</td>\n",
       "      <td>4037.593151</td>\n",
       "      <td>187474.602114</td>\n",
       "      <td>285248.867037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basse-Normandie</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.386823e+06</td>\n",
       "      <td>1.780635e+10</td>\n",
       "      <td>122829.920651</td>\n",
       "      <td>3688.358818</td>\n",
       "      <td>150571.399619</td>\n",
       "      <td>263736.945386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>2.480511e+06</td>\n",
       "      <td>3.233398e+10</td>\n",
       "      <td>228887.324618</td>\n",
       "      <td>6852.239326</td>\n",
       "      <td>202901.214557</td>\n",
       "      <td>276408.162313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region  road_density      length_m        area_m  \\\n",
       "3        Île-de-France      0.000227  2.744410e+06  1.206353e+10   \n",
       "15  Nord-Pas-de-Calais      0.000151  1.887368e+06  1.249483e+10   \n",
       "10     Haute-Normandie      0.000113  1.398489e+06  1.237197e+10   \n",
       "0               Alsace      0.000106  8.836421e+05  8.322648e+09   \n",
       "17            Picardie      0.000093  1.822331e+06  1.954720e+10   \n",
       "20         Rhône-Alpes      0.000090  4.039422e+06  4.497380e+10   \n",
       "13            Lorraine      0.000085  2.007468e+06  2.366142e+10   \n",
       "6             Bretagne      0.000085  2.333729e+06  2.760417e+10   \n",
       "4      Basse-Normandie      0.000078  1.386823e+06  1.780635e+10   \n",
       "16    Pays de la Loire      0.000077  2.480511e+06  3.233398e+10   \n",
       "\n",
       "       length_max  length_mean       diameter   longest_line  \n",
       "3    85932.399845  3076.692877  123934.499714  162432.991960  \n",
       "15  147881.271737  4015.676440  126130.541927  208410.677869  \n",
       "10  135138.054662  4994.602982  125508.904876  163440.964713  \n",
       "0   171172.687144  4374.466068  102940.396161  188809.381774  \n",
       "17  163238.986421  7854.875311  157760.172316  218702.689596  \n",
       "20  203474.560283  4047.517513  239295.676544  319508.048270  \n",
       "13  189457.934215  4562.427574  173570.336256  235280.099059  \n",
       "6   244626.451176  4037.593151  187474.602114  285248.867037  \n",
       "4   122829.920651  3688.358818  150571.399619  263736.945386  \n",
       "16  228887.324618  6852.239326  202901.214557  276408.162313  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(path = 'data/')\n",
    "df = data.create_df()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_num = Number_Stations(df_data=df, path_conf='params/config.json', length_to_use='longest_line', scenario=\"scenario1\")\n",
    "df_f = stations_num.final_station_calculation()\n",
    "\n",
    "df_f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.num_stations_2030.sum(), df_f.num_stations_2040.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_num.save_predictions(df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_num.get_scenario_output(df_f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(path = 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_files = data.get_shapefiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = data.get_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = data.get_jsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from station_finder.functions import StationLocator\n",
    "station_locator = StationLocator(shap_files, csvs)\n",
    "sorted_locations = station_locator.get_best_location(grid_size=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from station_finder.functions import Scenarios\n",
    "scenarios = Scenarios(shap_files, csvs)\n",
    "top_locations = scenarios.distribute_locations(sorted_locations = sorted_locations,region_breakdown = jsons['output_scenario1'][\"num_stations_2030\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from itertools import chain\n",
    "from shapely.geometry import Point\n",
    "from shapely import geometry\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "def merge_closest_points(top_locations: gpd.GeoDataFrame):\n",
    "    \"\"\"Merge close points into one station.\n",
    "\n",
    "    Args:\n",
    "        top_locations: geodataframe with top locations selected by model and their scores.\n",
    "    Returns:\n",
    "        polygones: final list of points with their score and number of merged points.\n",
    "    \"\"\"\n",
    "    top_locations = list(zip(top_locations[0], top_locations[1]))\n",
    "    distances = {}\n",
    "    for i in range(len(top_locations)):\n",
    "        distances.setdefault(i, [])\n",
    "        for j in range(len(top_locations)):\n",
    "            if top_locations[i][0].distance(top_locations[j][0]) <= 10000:\n",
    "                distance = top_locations[i][0].distance(top_locations[j][0])\n",
    "                distances[i].append((top_locations[j][0].xy[0][0], top_locations[j][0].xy[1][0]))\n",
    "    \n",
    "    for key, values in distances.items():\n",
    "        distances[key] = (values, len(values))\n",
    "    \n",
    "    distances = {k:v[0] for k, v in sorted(distances.items(), key=lambda item: item[1][1], reverse=True)}\n",
    "\n",
    "    distances_reduced = {}\n",
    "    distances_val = {}\n",
    "    for i in range(len(distances)):\n",
    "        if set(distances[i]).isdisjoint(set(list(chain(*list(distances_val.values()))))):\n",
    "            distances_val[i] = distances[i]\n",
    "            distances_reduced[i] = [Point(xy) for xy in distances[i]]\n",
    "    \n",
    "    polygones = []\n",
    "    for key, values in distances_reduced.items():\n",
    "        if len(values) == 1:\n",
    "            point = values[0]\n",
    "        elif len(values) == 2:\n",
    "            line = LineString([values[0], values[1]])\n",
    "            point = line.centroid\n",
    "        else:\n",
    "            point = geometry.Polygon(values).centroid\n",
    "        avg_score = np.mean([item[1] for item in top_locations if item[0] in values])\n",
    "        #if not any(p.equals(point) for p, _ in polygones):\n",
    "        polygones.append((point, avg_score, len(values)))\n",
    "    \n",
    "    return polygones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = merge_closest_points(top_locations)\n",
    "len(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = scenarios.fix_locations(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([k*j for i, j, k in new_points], 25), np.percentile([k*j for i, j, k in new_points], 50), np.percentile([k*j for i, j, k in new_points], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_station(new_points: list[object]):\n",
    "    \"\"\"Get the size of each station based on its score and number of merged stations.\n",
    "    Args:\n",
    "        new_points: list of locations, score and number of stations merged.\n",
    "    Returns:\n",
    "        new_points: list of locations and size of station\n",
    "    \"\"\"\n",
    "    thresholds = [\n",
    "        np.percentile([k*j for i, j, k in new_points], 50),\n",
    "        np.percentile([k*j for i, j, k in new_points], 75)\n",
    "        ]\n",
    "    final_points = []\n",
    "    for i in range(len(new_points)):\n",
    "        val = new_points[i][1]*new_points[i][2]\n",
    "        if val <= thresholds[0]:\n",
    "            final_points.append((new_points[i][0],\"small\"))\n",
    "        elif val <= thresholds[1]:\n",
    "            final_points.append((new_points[i][0],\"medium\"))\n",
    "        else:\n",
    "            final_points.append((new_points[i][0],\"large\"))\n",
    "    return final_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size_station(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([1 for i, j, k, n in new_points if n == \"large\"]), np.sum([1 for i, j, k, n in new_points if n == \"medium\"]), np.sum([1 for i, j, k, n in new_points if n == \"small\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_locations = list(zip(top_locations[0], top_locations[1]))\n",
    "distances = {}\n",
    "for i in range(len(sorted_locations)):\n",
    "    distances.setdefault(i, [])\n",
    "    for j in range(len(sorted_locations)):\n",
    "        if sorted_locations[i][0].distance(sorted_locations[j][0]) <= 10000:\n",
    "            distance = sorted_locations[i][0].distance(sorted_locations[j][0])\n",
    "            distances[i].append((sorted_locations[j][0].xy[0][0], sorted_locations[j][0].xy[1][0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in distances.items():\n",
    "    distances[key] = (values, len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_test = {k:v[0] for k, v in sorted(distances.items(), key=lambda item: item[1][1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from shapely.geometry import Point\n",
    "\n",
    "distances_reduced = {}\n",
    "distances_val = {}\n",
    "for i in range(len(distances_test)):\n",
    "    if set(distances_test[i]).isdisjoint(set(list(chain(*list(distances_val.values()))))):\n",
    "        distances_val[i] = distances_test[i]\n",
    "        distances_reduced[i] = [Point(xy) for xy in distances_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import geometry\n",
    "from shapely.geometry import LineString\n",
    "polygones = []\n",
    "for key, values in distances_reduced.items():\n",
    "    if len(values) == 1:\n",
    "        point = values\n",
    "    elif len(values) == 2:\n",
    "        line = LineString([values[0], values[1]])\n",
    "        point = line.centroid\n",
    "    else:\n",
    "        point = geometry.Polygon(values).centroid\n",
    "    avg_score = np.mean([item[1] for item in sorted_locations if item[0] in values])\n",
    "    #if not any(p.equals(point) for p, _ in polygones):\n",
    "    polygones.append((point, avg_score, len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(polygones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions (Not needed anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_freight_df(df, on_load=True):\n",
    "    \n",
    "#     df = df[['TIME', 'TIME.1', '2021']]\n",
    "    \n",
    "#     if on_load:\n",
    "#         freight_type = \"number_onload\"\n",
    "#     else:\n",
    "#         freight_type = \"number_offload\"\n",
    "        \n",
    "#     df.rename(columns={\"TIME\": \"geo_code\", \"TIME.1\": \"geo_labels\", \"2021\": freight_type}, inplace=True)\n",
    "#     df = df.iloc[1:]\n",
    "#     df_clean = df[df.geo_code.str.startswith(\"FR\").fillna(False)]\n",
    "#     df_clean.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "#     df_clean[freight_type] = df_clean[freight_type].astype('str')\n",
    "#     df_clean[freight_type] = df_clean[freight_type].str.replace('\\.0*$', '', regex=True)\n",
    "#     df_clean.loc[~(df_clean[freight_type].str.isdigit()), freight_type] = '0'\n",
    "#     df_clean[freight_type] = df_clean[freight_type].astype('int')\n",
    "    \n",
    "#     return df_clean\n",
    "\n",
    "# def department_region_map(path, df_fr):\n",
    "#     df_dpts_region = pd.read_csv(path)\n",
    "#     df_dpts_region.rename(columns={\"dep_name\":\"geo_labels\", \"region_name\":\"new_region_name\", \"old_region_name\": \"region\"}, inplace=True)\n",
    "#     df_final = pd.merge(df_fr, df_dpts_region[[\"geo_labels\", \"region\"]], how='left', on=['geo_labels'])\n",
    "#     df_final = df_final[~(df_final.geo_labels.str.endswith(\" \"))]\n",
    "#     return df_final\n",
    "\n",
    "# def merge_freight(path, df_on, df_off):\n",
    "    \n",
    "#     df_onload_fr = clean_freight_df(df_on, on_load=True)\n",
    "#     df_offload_fr = clean_freight_df(df_off, on_load=False)\n",
    "\n",
    "#     df_fr = pd.merge(df_onload_fr, df_offload_fr, how='inner', on=['geo_code', 'geo_labels'])\n",
    "#     df_fr['total_load'] = df_fr.number_offload + df_fr.number_onload \n",
    "    \n",
    "#     df_fr['geo_labels'] = [c[0] for c in df_fr['geo_labels'].str.split(\"(\")]\n",
    "#     df_fr = department_region_map(path, df_fr)\n",
    "#     df_fr = df_fr.groupby(\"region\")[\"total_load\"].sum().reset_index()\n",
    "#     df_fr[\"full_load\"] = df_fr[\"total_load\"].sum()   \n",
    "#     df_fr[\"perc_load\"] = df_fr[\"total_load\"]/df_fr[\"full_load\"]\n",
    "\n",
    "#     return df_fr\n",
    "\n",
    "# def calculate_trucks_stations_peryear(df, year=2030):\n",
    "    \n",
    "#     autonomy_high_ms = market_share[0]/sum(market_share)\n",
    "#     autonomy_medium_ms =market_share[1]/sum(market_share)\n",
    "#     autonomy_low_ms = market_share[2]/sum(market_share)\n",
    "#     autonomy_high_km = autonomy_share[0]\n",
    "#     autonomy_medium_km = autonomy_share[1]\n",
    "#     autonomy_low_km = autonomy_share[2]\n",
    "    \n",
    "#     if (year not in [2030, 2040]):\n",
    "#         year = 2030\n",
    "        \n",
    "#     if year==2030:\n",
    "#         H2_trucks_num = H2_trucks_2030\n",
    "#     else:\n",
    "#         H2_trucks_num = H2_trucks_2040\n",
    "        \n",
    "#     df[\"h2_num_\"+str(year)] = H2_trucks_num*df[\"perc_load\"]\n",
    "#     df[\"R_\"+str(year)+\"_high_aut\"] = autonomy_high_ms*df[\"h2_num_\"+str(year)]*df[\"avg_distance_high_aut\"]/autonomy_high_km\n",
    "#     df[\"R_\"+str(year)+\"_mid_aut\"] = autonomy_medium_ms*df[\"h2_num_\"+str(year)]*df[\"avg_distance_midlow_aut\"]/autonomy_medium_km\n",
    "#     df[\"R_\"+str(year)+\"_low_aut\"] = autonomy_low_ms*df[\"h2_num_\"+str(year)]*df[\"avg_distance_midlow_aut\"]/autonomy_low_km\n",
    "#     df[\"R_\"+str(year)+\"_total\"] = df[\"R_\"+str(year)+\"_high_aut\"] + df[\"R_\"+str(year)+\"_mid_aut\"] + df[\"R_\"+str(year)+\"_low_aut\"]\n",
    "#     df[\"C_\"+str(year)] = open_time/avg_time_fill\n",
    "    \n",
    "#     return df\n",
    "    \n",
    "# def calculate_stations(df, year=2030):\n",
    "    \n",
    "#     if (year not in [2030, 2040]):\n",
    "#         year = 2030\n",
    "        \n",
    "#     df[\"num_stations_\"+str(year)] = (df[\"R_\"+str(year)+\"_total\"] / df[\"C_\"+str(year)]).round().astype(int)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# def calculate_number_stations(df, length_to_use='longest_line'):\n",
    "#     \"\"\"_summary_\n",
    "\n",
    "#     Args:\n",
    "#         df : _description_\n",
    "#         length_to_use : can be 'longest_line', 'diameter' or 'length_max'.\n",
    "\n",
    "#     Returns:\n",
    "#         _type_: _description_\n",
    "#     \"\"\"\n",
    "\n",
    "#     if (length_to_use not in ['longest_line', 'diameter', 'length_max']):\n",
    "#         length_to_use = 'longest_line'\n",
    "        \n",
    "#     df[\"max_length_drive\"] = max_hours_drive*avg_speed_kmh\n",
    "#     df[[\"length_max\", \"length_mean\", \"diameter\", \"longest_line\"]] = df[[\"length_max\", \"length_mean\", \"diameter\", \"longest_line\"]]/1e3\n",
    "#     df[\"avg_distance_high_aut\"] = df[[\"max_length_drive\", length_to_use]].min(axis=1) # This would be updated either by diameter or longest point\n",
    "#     df[\"avg_distance_midlow_aut\"] = 0.6*df[\"avg_distance_high_aut\"]#df_new[[\"max_length_drive\", \"length_mean\"]].min(axis=1)\n",
    "    \n",
    "#     df = calculate_trucks_stations_peryear(df, year=2030)\n",
    "#     df = calculate_trucks_stations_peryear(df, year=2040)\n",
    "    \n",
    "#     df = calculate_stations(df, year=2030)\n",
    "#     df = calculate_stations(df, year=2040)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute functions (Not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_conf = \"params/config.json\"\n",
    "# conf = json.load(open(path_conf, \"r\"))\n",
    "# locals().update(conf)\n",
    "\n",
    "# df_on = pd.read_excel(path_on_freight, sheet_name='Sheet 1', skiprows=8)\n",
    "# df_off = pd.read_excel(path_off_freight, sheet_name='Sheet 1', skiprows=8)\n",
    "\n",
    "# df_fr = merge_freight(path_region_dpt_map, df_on, df_off)\n",
    "# df_new = pd.merge(df, df_fr[[\"region\", \"perc_load\"]], how=\"left\", on=\"region\")\n",
    "\n",
    "# df_new = calculate_number_stations(df_new)\n",
    "\n",
    "# display(df_fr.head(10))\n",
    "\n",
    "# df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>size</th>\n",
       "      <th>score</th>\n",
       "      <th>2040_demand</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (349897.3828152193 6787126.496840154)</td>\n",
       "      <td>large</td>\n",
       "      <td>28.472269</td>\n",
       "      <td>6519.608713</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (859374.1128636684 6509910.7609227905)</td>\n",
       "      <td>large</td>\n",
       "      <td>28.125491</td>\n",
       "      <td>6440.203162</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (679889.884000003 6858774.466)</td>\n",
       "      <td>large</td>\n",
       "      <td>25.493494</td>\n",
       "      <td>5837.525922</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (675647.5701007999 6864404.35065435)</td>\n",
       "      <td>large</td>\n",
       "      <td>25.461621</td>\n",
       "      <td>5830.227398</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (501897.7601 6927171.4867)</td>\n",
       "      <td>large</td>\n",
       "      <td>24.862709</td>\n",
       "      <td>5693.087935</td>\n",
       "      <td>2030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>POINT (516781.99014209316 6358773.947951271)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400367</td>\n",
       "      <td>320.657431</td>\n",
       "      <td>2040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>POINT (688246.075000003 6169273.742)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.284057</td>\n",
       "      <td>294.024569</td>\n",
       "      <td>2040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>POINT (571431.4716471918 6328819.535394812)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.261500</td>\n",
       "      <td>288.859551</td>\n",
       "      <td>2040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>POINT (528785.5475687049 6331548.799938178)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008440</td>\n",
       "      <td>230.913529</td>\n",
       "      <td>2040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>POINT (561729.057999998 6258014.876)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.713369</td>\n",
       "      <td>163.348038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           points   size      score  \\\n",
       "0     POINT (349897.3828152193 6787126.496840154)  large  28.472269   \n",
       "1    POINT (859374.1128636684 6509910.7609227905)  large  28.125491   \n",
       "2            POINT (679889.884000003 6858774.466)  large  25.493494   \n",
       "3      POINT (675647.5701007999 6864404.35065435)  large  25.461621   \n",
       "4                POINT (501897.7601 6927171.4867)  large  24.862709   \n",
       "..                                            ...    ...        ...   \n",
       "278  POINT (516781.99014209316 6358773.947951271)    NaN   1.400367   \n",
       "279          POINT (688246.075000003 6169273.742)    NaN   1.284057   \n",
       "280   POINT (571431.4716471918 6328819.535394812)    NaN   1.261500   \n",
       "281   POINT (528785.5475687049 6331548.799938178)    NaN   1.008440   \n",
       "282          POINT (561729.057999998 6258014.876)    NaN   0.713369   \n",
       "\n",
       "     2040_demand    year  \n",
       "0    6519.608713  2030.0  \n",
       "1    6440.203162  2030.0  \n",
       "2    5837.525922  2030.0  \n",
       "3    5830.227398  2030.0  \n",
       "4    5693.087935  2030.0  \n",
       "..           ...     ...  \n",
       "278   320.657431  2040.0  \n",
       "279   294.024569  2040.0  \n",
       "280   288.859551  2040.0  \n",
       "281   230.913529  2040.0  \n",
       "282   163.348038     NaN  \n",
       "\n",
       "[283 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       POINT (349897.3828152193 6787126.496840154)\n",
       "1      POINT (859374.1128636684 6509910.7609227905)\n",
       "2              POINT (679889.884000003 6858774.466)\n",
       "3        POINT (675647.5701007999 6864404.35065435)\n",
       "4                  POINT (501897.7601 6927171.4867)\n",
       "                           ...                     \n",
       "278    POINT (516781.99014209316 6358773.947951271)\n",
       "279            POINT (688246.075000003 6169273.742)\n",
       "280     POINT (571431.4716471918 6328819.535394812)\n",
       "281     POINT (528785.5475687049 6331548.799938178)\n",
       "282            POINT (561729.057999998 6258014.876)\n",
       "Name: points, Length: 283, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_points.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost = pd.read_csv('app/pages/utils/cases_csv_part3/cost_yearly_scenario3.csv')\n",
    "df_cost.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "df_final_points = pd.read_csv('app/pages/utils/cases_csv_part3/final_points_scenario3.csv')\n",
    "df_final_points.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_final_points['points'] = df_final_points['points'].apply(wkt.loads)\n",
    "\n",
    "df_points = gpd.GeoDataFrame(df_final_points, geometry=df_final_points.points).set_crs('2154')\n",
    "df_points = df_points[~ df_points.year.isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geometry list from the GeoDataFrame\n",
    "# colors = ['#FF0000', # red\n",
    "#           '#FF7F00', # orange\n",
    "#           '#FFFF00', # yellow\n",
    "#           '#00FF00', # green\n",
    "#           '#00FFFF', # cyan\n",
    "#           '#0000FF', # blue\n",
    "#           '#8B00FF', # violet\n",
    "#           '#FF00FF', # magenta\n",
    "#           '#FF007F', # rose\n",
    "#           '#808080', # gray\n",
    "#           '#FFFFFF'] # white\n",
    "\n",
    "colors = ['#2C3E50',\n",
    "          '#C0392B',\n",
    "          '#E74C3C',\n",
    "          '#9B59B6',\n",
    "          '#8E44AD',\n",
    "          '#2980B9',\n",
    "          '#3498DB',\n",
    "          '#27AE60',\n",
    "          '#F1C40F',\n",
    "          '#E67E22',\n",
    "          '#D35400']\n",
    "\n",
    "# Method 1\n",
    "# # Iterate through list and add a marker for each volcano, color-coded by its type.\n",
    "# m = folium.Map(location=france_center, zoom_start=6, tiles='cartodbpositron')\n",
    "# for idx, year_i in enumerate(set(df_points.year.astype(int))):\n",
    "#     type_color = colors[idx]\n",
    "#     df_p = df_points[df_points.year==year_i]\n",
    "#     geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in df_p.geometry]\n",
    "#     for coordinates in geo_df_list:\n",
    "#         # assign a color marker for the type of volcano, Strato being the most common\n",
    "#         # Place the markers with the popup labels and data\n",
    "#         m.add_child(\n",
    "#             folium.Marker(\n",
    "#                 location=coordinates,\n",
    "#                 # popup=\n",
    "#                 #     \"Year: \" + str(geo_df.Year[i]) + \"<br>\"\n",
    "#                 #     + \"Name: \" + str(geo_df.Name[i]) + \"<br>\"\n",
    "#                 #     + \"Country: \" + str(geo_df.Country[i]) + \"<br>\"\n",
    "#                 #     + \"Type: \" + str(geo_df.Type[i]) + \"<br>\"\n",
    "#                     # + \"Coordinates: \" + str(geo_df_list[i]),\n",
    "#                 icon=folium.Icon(color=\"%s\" % type_color) \n",
    "#             )\n",
    "#         )    \n",
    "\n",
    "\n",
    "# # Method 2\n",
    "\n",
    "m = folium.Map(location=france_center, zoom_start=5, tiles='cartodbpositron')\n",
    "for idx, year_i in enumerate(set(df_points.year.astype(int))):\n",
    "    type_color = colors[idx]\n",
    "    df_p = df_points[df_points.year==year_i]\n",
    "    geo_df_list = [[point.xy[1][0], point.xy[0][0]] for point in df_p.geometry]\n",
    "\n",
    "    top_2030 = folium.GeoJson(df_p.geometry,\n",
    "                              marker = folium.CircleMarker(\n",
    "                                      radius = 3,\n",
    "                                      weight = 0,\n",
    "                                      fill_color = colors[idx], \n",
    "                                      fill_opacity = 0.8)                   \n",
    "                                  ).add_to(m)\n",
    "\n",
    "colormap = cm.LinearColormap(colors=colors,\n",
    "                             index=set(df_points.year.astype(int)), vmin=int(2030), vmax=int(2040),\n",
    "                             caption='Total Standard deviation at the point[mm]',\n",
    "                             ).add_to(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f95b24995c6ef655ffa9d54bd829b00250e14679292be6736d298f940e6170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
