{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_preprocess.functions import Data\n",
    "from load_preprocess.predictions import Number_Stations\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import config\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import LineString, mapping\n",
    "from itertools import combinations\n",
    "import re\n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.86s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>road_density</th>\n",
       "      <th>length_m</th>\n",
       "      <th>area_m</th>\n",
       "      <th>length_max</th>\n",
       "      <th>length_mean</th>\n",
       "      <th>diameter</th>\n",
       "      <th>longest_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>2.744410e+06</td>\n",
       "      <td>1.206353e+10</td>\n",
       "      <td>85932.399845</td>\n",
       "      <td>3076.692877</td>\n",
       "      <td>123934.499714</td>\n",
       "      <td>162432.991960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nord-Pas-de-Calais</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1.887368e+06</td>\n",
       "      <td>1.249483e+10</td>\n",
       "      <td>147881.271737</td>\n",
       "      <td>4015.676440</td>\n",
       "      <td>126130.541927</td>\n",
       "      <td>208410.677869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Haute-Normandie</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1.398489e+06</td>\n",
       "      <td>1.237197e+10</td>\n",
       "      <td>135138.054662</td>\n",
       "      <td>4994.602982</td>\n",
       "      <td>125508.904876</td>\n",
       "      <td>163440.964713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alsace</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>8.836421e+05</td>\n",
       "      <td>8.322648e+09</td>\n",
       "      <td>171172.687144</td>\n",
       "      <td>4374.466068</td>\n",
       "      <td>102940.396161</td>\n",
       "      <td>188809.381774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Picardie</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>1.822331e+06</td>\n",
       "      <td>1.954720e+10</td>\n",
       "      <td>163238.986421</td>\n",
       "      <td>7854.875311</td>\n",
       "      <td>157760.172316</td>\n",
       "      <td>218702.689596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rhône-Alpes</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>4.039422e+06</td>\n",
       "      <td>4.497380e+10</td>\n",
       "      <td>203474.560283</td>\n",
       "      <td>4047.517513</td>\n",
       "      <td>239295.676544</td>\n",
       "      <td>319508.048270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lorraine</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.007468e+06</td>\n",
       "      <td>2.366142e+10</td>\n",
       "      <td>189457.934215</td>\n",
       "      <td>4562.427574</td>\n",
       "      <td>173570.336256</td>\n",
       "      <td>235280.099059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bretagne</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.333729e+06</td>\n",
       "      <td>2.760417e+10</td>\n",
       "      <td>244626.451176</td>\n",
       "      <td>4037.593151</td>\n",
       "      <td>187474.602114</td>\n",
       "      <td>285248.867037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basse-Normandie</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.386823e+06</td>\n",
       "      <td>1.780635e+10</td>\n",
       "      <td>122829.920651</td>\n",
       "      <td>3688.358818</td>\n",
       "      <td>150571.399619</td>\n",
       "      <td>263736.945386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>2.480511e+06</td>\n",
       "      <td>3.233398e+10</td>\n",
       "      <td>228887.324618</td>\n",
       "      <td>6852.239326</td>\n",
       "      <td>202901.214557</td>\n",
       "      <td>276408.162313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region  road_density      length_m        area_m  \\\n",
       "3        Île-de-France      0.000227  2.744410e+06  1.206353e+10   \n",
       "15  Nord-Pas-de-Calais      0.000151  1.887368e+06  1.249483e+10   \n",
       "10     Haute-Normandie      0.000113  1.398489e+06  1.237197e+10   \n",
       "0               Alsace      0.000106  8.836421e+05  8.322648e+09   \n",
       "17            Picardie      0.000093  1.822331e+06  1.954720e+10   \n",
       "20         Rhône-Alpes      0.000090  4.039422e+06  4.497380e+10   \n",
       "13            Lorraine      0.000085  2.007468e+06  2.366142e+10   \n",
       "6             Bretagne      0.000085  2.333729e+06  2.760417e+10   \n",
       "4      Basse-Normandie      0.000078  1.386823e+06  1.780635e+10   \n",
       "16    Pays de la Loire      0.000077  2.480511e+06  3.233398e+10   \n",
       "\n",
       "       length_max  length_mean       diameter   longest_line  \n",
       "3    85932.399845  3076.692877  123934.499714  162432.991960  \n",
       "15  147881.271737  4015.676440  126130.541927  208410.677869  \n",
       "10  135138.054662  4994.602982  125508.904876  163440.964713  \n",
       "0   171172.687144  4374.466068  102940.396161  188809.381774  \n",
       "17  163238.986421  7854.875311  157760.172316  218702.689596  \n",
       "20  203474.560283  4047.517513  239295.676544  319508.048270  \n",
       "13  189457.934215  4562.427574  173570.336256  235280.099059  \n",
       "6   244626.451176  4037.593151  187474.602114  285248.867037  \n",
       "4   122829.920651  3688.358818  150571.399619  263736.945386  \n",
       "16  228887.324618  6852.239326  202901.214557  276408.162313  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(path = 'data/')\n",
    "df = data.create_df()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_num = Number_Stations(df_data=df, path_conf='params/config.json', length_to_use='longest_line', scenario=\"scenario1\")\n",
    "df_f = stations_num.final_station_calculation()\n",
    "\n",
    "df_f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.num_stations_2030.sum(), df_f.num_stations_2040.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_num.save_predictions(df_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_num.get_scenario_output(df_f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(path = 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_files = data.get_shapefiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = data.get_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = data.get_jsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from station_finder.functions import StationLocator\n",
    "station_locator = StationLocator(shap_files, csvs)\n",
    "sorted_locations = station_locator.get_best_location(grid_size=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from station_finder.functions import Scenarios\n",
    "scenarios = Scenarios(shap_files, csvs)\n",
    "top_locations = scenarios.distribute_locations(sorted_locations = sorted_locations,region_breakdown = jsons['output_scenario1'][\"num_stations_2030\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from itertools import chain\n",
    "from shapely.geometry import Point\n",
    "from shapely import geometry\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "def merge_closest_points(top_locations: gpd.GeoDataFrame):\n",
    "    \"\"\"Merge close points into one station.\n",
    "\n",
    "    Args:\n",
    "        top_locations: geodataframe with top locations selected by model and their scores.\n",
    "    Returns:\n",
    "        polygones: final list of points with their score and number of merged points.\n",
    "    \"\"\"\n",
    "    top_locations = list(zip(top_locations[0], top_locations[1]))\n",
    "    distances = {}\n",
    "    for i in range(len(top_locations)):\n",
    "        distances.setdefault(i, [])\n",
    "        for j in range(len(top_locations)):\n",
    "            if top_locations[i][0].distance(top_locations[j][0]) <= 10000:\n",
    "                distance = top_locations[i][0].distance(top_locations[j][0])\n",
    "                distances[i].append((top_locations[j][0].xy[0][0], top_locations[j][0].xy[1][0]))\n",
    "    \n",
    "    for key, values in distances.items():\n",
    "        distances[key] = (values, len(values))\n",
    "    \n",
    "    distances = {k:v[0] for k, v in sorted(distances.items(), key=lambda item: item[1][1], reverse=True)}\n",
    "\n",
    "    distances_reduced = {}\n",
    "    distances_val = {}\n",
    "    for i in range(len(distances)):\n",
    "        if set(distances[i]).isdisjoint(set(list(chain(*list(distances_val.values()))))):\n",
    "            distances_val[i] = distances[i]\n",
    "            distances_reduced[i] = [Point(xy) for xy in distances[i]]\n",
    "    \n",
    "    polygones = []\n",
    "    for key, values in distances_reduced.items():\n",
    "        if len(values) == 1:\n",
    "            point = values[0]\n",
    "        elif len(values) == 2:\n",
    "            line = LineString([values[0], values[1]])\n",
    "            point = line.centroid\n",
    "        else:\n",
    "            point = geometry.Polygon(values).centroid\n",
    "        avg_score = np.mean([item[1] for item in top_locations if item[0] in values])\n",
    "        #if not any(p.equals(point) for p, _ in polygones):\n",
    "        polygones.append((point, avg_score, len(values)))\n",
    "    \n",
    "    return polygones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = merge_closest_points(top_locations)\n",
    "len(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = scenarios.fix_locations(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([k*j for i, j, k in new_points], 25), np.percentile([k*j for i, j, k in new_points], 50), np.percentile([k*j for i, j, k in new_points], 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_station(new_points: list[object]):\n",
    "    \"\"\"Get the size of each station based on its score and number of merged stations.\n",
    "    Args:\n",
    "        new_points: list of locations, score and number of stations merged.\n",
    "    Returns:\n",
    "        new_points: list of locations and size of station\n",
    "    \"\"\"\n",
    "    thresholds = [\n",
    "        np.percentile([k*j for i, j, k in new_points], 50),\n",
    "        np.percentile([k*j for i, j, k in new_points], 75)\n",
    "        ]\n",
    "    final_points = []\n",
    "    for i in range(len(new_points)):\n",
    "        val = new_points[i][1]*new_points[i][2]\n",
    "        if val <= thresholds[0]:\n",
    "            final_points.append((new_points[i][0],\"small\"))\n",
    "        elif val <= thresholds[1]:\n",
    "            final_points.append((new_points[i][0],\"medium\"))\n",
    "        else:\n",
    "            final_points.append((new_points[i][0],\"large\"))\n",
    "    return final_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size_station(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([1 for i, j, k, n in new_points if n == \"large\"]), np.sum([1 for i, j, k, n in new_points if n == \"medium\"]), np.sum([1 for i, j, k, n in new_points if n == \"small\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_locations = list(zip(top_locations[0], top_locations[1]))\n",
    "distances = {}\n",
    "for i in range(len(sorted_locations)):\n",
    "    distances.setdefault(i, [])\n",
    "    for j in range(len(sorted_locations)):\n",
    "        if sorted_locations[i][0].distance(sorted_locations[j][0]) <= 10000:\n",
    "            distance = sorted_locations[i][0].distance(sorted_locations[j][0])\n",
    "            distances[i].append((sorted_locations[j][0].xy[0][0], sorted_locations[j][0].xy[1][0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in distances.items():\n",
    "    distances[key] = (values, len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_test = {k:v[0] for k, v in sorted(distances.items(), key=lambda item: item[1][1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from shapely.geometry import Point\n",
    "\n",
    "distances_reduced = {}\n",
    "distances_val = {}\n",
    "for i in range(len(distances_test)):\n",
    "    if set(distances_test[i]).isdisjoint(set(list(chain(*list(distances_val.values()))))):\n",
    "        distances_val[i] = distances_test[i]\n",
    "        distances_reduced[i] = [Point(xy) for xy in distances_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import geometry\n",
    "from shapely.geometry import LineString\n",
    "polygones = []\n",
    "for key, values in distances_reduced.items():\n",
    "    if len(values) == 1:\n",
    "        point = values\n",
    "    elif len(values) == 2:\n",
    "        line = LineString([values[0], values[1]])\n",
    "        point = line.centroid\n",
    "    else:\n",
    "        point = geometry.Polygon(values).centroid\n",
    "    avg_score = np.mean([item[1] for item in sorted_locations if item[0] in values])\n",
    "    #if not any(p.equals(point) for p, _ in polygones):\n",
    "    polygones.append((point, avg_score, len(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(polygones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions (Not needed anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_freight_df(df, on_load=True):\n",
    "    \n",
    "#     df = df[['TIME', 'TIME.1', '2021']]\n",
    "    \n",
    "#     if on_load:\n",
    "#         freight_type = \"number_onload\"\n",
    "#     else:\n",
    "#         freight_type = \"number_offload\"\n",
    "        \n",
    "#     df.rename(columns={\"TIME\": \"geo_code\", \"TIME.1\": \"geo_labels\", \"2021\": freight_type}, inplace=True)\n",
    "#     df = df.iloc[1:]\n",
    "#     df_clean = df[df.geo_code.str.startswith(\"FR\").fillna(False)]\n",
    "#     df_clean.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "#     df_clean[freight_type] = df_clean[freight_type].astype('str')\n",
    "#     df_clean[freight_type] = df_clean[freight_type].str.replace('\\.0*$', '', regex=True)\n",
    "#     df_clean.loc[~(df_clean[freight_type].str.isdigit()), freight_type] = '0'\n",
    "#     df_clean[freight_type] = df_clean[freight_type].astype('int')\n",
    "    \n",
    "#     return df_clean\n",
    "\n",
    "# def department_region_map(path, df_fr):\n",
    "#     df_dpts_region = pd.read_csv(path)\n",
    "#     df_dpts_region.rename(columns={\"dep_name\":\"geo_labels\", \"region_name\":\"new_region_name\", \"old_region_name\": \"region\"}, inplace=True)\n",
    "#     df_final = pd.merge(df_fr, df_dpts_region[[\"geo_labels\", \"region\"]], how='left', on=['geo_labels'])\n",
    "#     df_final = df_final[~(df_final.geo_labels.str.endswith(\" \"))]\n",
    "#     return df_final\n",
    "\n",
    "# def merge_freight(path, df_on, df_off):\n",
    "    \n",
    "#     df_onload_fr = clean_freight_df(df_on, on_load=True)\n",
    "#     df_offload_fr = clean_freight_df(df_off, on_load=False)\n",
    "\n",
    "#     df_fr = pd.merge(df_onload_fr, df_offload_fr, how='inner', on=['geo_code', 'geo_labels'])\n",
    "#     df_fr['total_load'] = df_fr.number_offload + df_fr.number_onload \n",
    "    \n",
    "#     df_fr['geo_labels'] = [c[0] for c in df_fr['geo_labels'].str.split(\"(\")]\n",
    "#     df_fr = department_region_map(path, df_fr)\n",
    "#     df_fr = df_fr.groupby(\"region\")[\"total_load\"].sum().reset_index()\n",
    "#     df_fr[\"full_load\"] = df_fr[\"total_load\"].sum()   \n",
    "#     df_fr[\"perc_load\"] = df_fr[\"total_load\"]/df_fr[\"full_load\"]\n",
    "\n",
    "#     return df_fr\n",
    "\n",
    "# def calculate_trucks_stations_peryear(df, year=2030):\n",
    "    \n",
    "#     autonomy_high_ms = market_share[0]/sum(market_share)\n",
    "#     autonomy_medium_ms =market_share[1]/sum(market_share)\n",
    "#     autonomy_low_ms = market_share[2]/sum(market_share)\n",
    "#     autonomy_high_km = autonomy_share[0]\n",
    "#     autonomy_medium_km = autonomy_share[1]\n",
    "#     autonomy_low_km = autonomy_share[2]\n",
    "    \n",
    "#     if (year not in [2030, 2040]):\n",
    "#         year = 2030\n",
    "        \n",
    "#     if year==2030:\n",
    "#         H2_trucks_num = H2_trucks_2030\n",
    "#     else:\n",
    "#         H2_trucks_num = H2_trucks_2040\n",
    "        \n",
    "#     df[\"h2_num_\"+str(year)] = H2_trucks_num*df[\"perc_load\"]\n",
    "#     df[\"R_\"+str(year)+\"_high_aut\"] = autonomy_high_ms*df[\"h2_num_\"+str(year)]*df[\"avg_distance_high_aut\"]/autonomy_high_km\n",
    "#     df[\"R_\"+str(year)+\"_mid_aut\"] = autonomy_medium_ms*df[\"h2_num_\"+str(year)]*df[\"avg_distance_midlow_aut\"]/autonomy_medium_km\n",
    "#     df[\"R_\"+str(year)+\"_low_aut\"] = autonomy_low_ms*df[\"h2_num_\"+str(year)]*df[\"avg_distance_midlow_aut\"]/autonomy_low_km\n",
    "#     df[\"R_\"+str(year)+\"_total\"] = df[\"R_\"+str(year)+\"_high_aut\"] + df[\"R_\"+str(year)+\"_mid_aut\"] + df[\"R_\"+str(year)+\"_low_aut\"]\n",
    "#     df[\"C_\"+str(year)] = open_time/avg_time_fill\n",
    "    \n",
    "#     return df\n",
    "    \n",
    "# def calculate_stations(df, year=2030):\n",
    "    \n",
    "#     if (year not in [2030, 2040]):\n",
    "#         year = 2030\n",
    "        \n",
    "#     df[\"num_stations_\"+str(year)] = (df[\"R_\"+str(year)+\"_total\"] / df[\"C_\"+str(year)]).round().astype(int)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# def calculate_number_stations(df, length_to_use='longest_line'):\n",
    "#     \"\"\"_summary_\n",
    "\n",
    "#     Args:\n",
    "#         df : _description_\n",
    "#         length_to_use : can be 'longest_line', 'diameter' or 'length_max'.\n",
    "\n",
    "#     Returns:\n",
    "#         _type_: _description_\n",
    "#     \"\"\"\n",
    "\n",
    "#     if (length_to_use not in ['longest_line', 'diameter', 'length_max']):\n",
    "#         length_to_use = 'longest_line'\n",
    "        \n",
    "#     df[\"max_length_drive\"] = max_hours_drive*avg_speed_kmh\n",
    "#     df[[\"length_max\", \"length_mean\", \"diameter\", \"longest_line\"]] = df[[\"length_max\", \"length_mean\", \"diameter\", \"longest_line\"]]/1e3\n",
    "#     df[\"avg_distance_high_aut\"] = df[[\"max_length_drive\", length_to_use]].min(axis=1) # This would be updated either by diameter or longest point\n",
    "#     df[\"avg_distance_midlow_aut\"] = 0.6*df[\"avg_distance_high_aut\"]#df_new[[\"max_length_drive\", \"length_mean\"]].min(axis=1)\n",
    "    \n",
    "#     df = calculate_trucks_stations_peryear(df, year=2030)\n",
    "#     df = calculate_trucks_stations_peryear(df, year=2040)\n",
    "    \n",
    "#     df = calculate_stations(df, year=2030)\n",
    "#     df = calculate_stations(df, year=2040)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute functions (Not needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_conf = \"params/config.json\"\n",
    "# conf = json.load(open(path_conf, \"r\"))\n",
    "# locals().update(conf)\n",
    "\n",
    "# df_on = pd.read_excel(path_on_freight, sheet_name='Sheet 1', skiprows=8)\n",
    "# df_off = pd.read_excel(path_off_freight, sheet_name='Sheet 1', skiprows=8)\n",
    "\n",
    "# df_fr = merge_freight(path_region_dpt_map, df_on, df_off)\n",
    "# df_new = pd.merge(df, df_fr[[\"region\", \"perc_load\"]], how=\"left\", on=\"region\")\n",
    "\n",
    "# df_new = calculate_number_stations(df_new)\n",
    "\n",
    "# display(df_fr.head(10))\n",
    "\n",
    "# df_new.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f95b24995c6ef655ffa9d54bd829b00250e14679292be6736d298f940e6170"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
